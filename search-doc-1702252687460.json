{"searchDocs":[{"title":"Desktop","type":0,"sectionRef":"#","url":"/docs/configuration/desktop/","content":"Desktop Coming soon...","keywords":"","version":"Next"},{"title":"Server","type":0,"sectionRef":"#","url":"/docs/configuration/server/","content":"","keywords":"","version":"Next"},{"title":"Configuration​","type":1,"pageTitle":"Server","url":"/docs/configuration/server/#configuration","content":" ","version":"Next","tagName":"h2"},{"title":"Server configuration​","type":1,"pageTitle":"Server","url":"/docs/configuration/server/#server-configuration","content":" Environment Variable\tDescription\tDefaultICE_SERVERS\tA JSON string containing a list of ICE servers to use for the web clients. See ICE Servers below for more details\t[] AUTH_REQUIRED\tBoolean indicating whether authentication is required for both desktop\tfalse STUN_PORT\tPort number to run the integrated STUN server. Set to -1 to disable\t-1 HTTP_PORT\tPort number to run the HTTP server off of\t8080 SERVE_TLS\tBoolean indicating whether or not to serve the web client and mqtt connection over HTTPS\tfalse TLS_PORT\tWhat port to run the TLS server off of for the HTTPS connections\t8443 TLS_KEY\tTLS key in PEM format\tdisabled TLS_CERT\tTLS certificate in PEM format. If the certificate is signed by a certificate authority, the file should be the concatenation of the server's certificate, any intermediates, and the CA's certificate.\tdisabled  ","version":"Next","tagName":"h3"},{"title":"Desktop authentication​","type":1,"pageTitle":"Server","url":"/docs/configuration/server/#desktop-authentication","content":" Environment Variable\tDescription\tDefaultDESKTOP_PSK\tPreshared key with all desktops used for secure registration and communication. If not provided, desktop authentication is disabled.\tdisabled  ","version":"Next","tagName":"h3"},{"title":"Client authentication​","type":1,"pageTitle":"Server","url":"/docs/configuration/server/#client-authentication","content":" Environment Variable\tDescription\tDefaultCLIENT_PSK\tIf provided, will require that the desktop client provide a preshared key (password) before being allowed to connect to the server or any of the Desktops. If not provided and OIDC_SERVER is, OpenID Connect will be used instead, otherwise no auth will be required.\tdisabled OIDC_SERVER\tOpenID Connect issuer url. Ex. http://keycloak.example.com/realms/my_realm. If set will redirect the client to the auth provider for login. See OpenID Configuration below for more details.\tdisabled OIDC_CLIENT_ID\tOpenID Connect client id to be used during the login. See OpenID Configuration below for more details.\tdisabled  ","version":"Next","tagName":"h3"},{"title":"ICE Servers​","type":1,"pageTitle":"Server","url":"/docs/configuration/server/#ice-servers","content":" The ICE servers configuration is a JSON string containing an array of objects, each describing one server which may be used by the ICE agent; these are typically STUN and/or TURN servers. If this isn't specified, the connection attempt will be made with no STUN or TURN server available, which limits the connection to local peers. Each object may have the following properties:  credential Optional: The credential to use when logging into the server. This is only used if the object represents a TURN server. credentialType Optional: If the object represents a TURN server, this attribute specifies what kind of credential is to be used when connecting. The default is &quot;password&quot;. urls: This required property is an array of strings, each specifying a URL which can be used to connect to the server. Should be in the format &quot;stun:stun.example.org&quot; or &quot;turn:turn.example.org&quot;, with an optional transport parameter (&quot;turns&quot; or &quot;stuns&quot;, respectively) and an optional port number. If no transport parameter is specified, the server is assumed to be a STUN server. If no port is specified, the default port for the specified transport protocol is used. If multiple URLs are given, they are tried in the order listed until one succeeds. username Optional: If the object represents a TURN server, then this is the username to use during the authentication.  See the ICE Servers section of the connection guide for more details and examples on running your own ICE servers.  ","version":"Next","tagName":"h2"},{"title":"OpenID Connect​","type":1,"pageTitle":"Server","url":"/docs/configuration/server/#openid-connect","content":" The OpenID Connect configuration is used to authenticate the client using an external provider. The client will be redirected to the provider's login page and then redirected back to the client with an authorization code. The client will then exchange the authorization code for an id token and use that to authenticate with the server. The server will then validate the id token against the issuer to validate the connection.  The OpenID Connect client configured must support the authorization_code grant type and the openid scope, as well as support the code response type. It must also be configured with a token endpoint authentication method of &quot;none&quot; to enable the authorization code exchange without a client secret. The client must also be configured with the redirect URI https://&lt;server&gt;/oidc-callback. The &lt;server&gt; is determined from where the client is served from. For example, If the client is served from https://pod-arcade.example.com, then the redirect URI would be https://pod-arcade.example.com/oidc-callback. ","version":"Next","tagName":"h2"},{"title":"Peer-to-Peer Connection","type":0,"sectionRef":"#","url":"/docs/design/peer-to-peer/","content":"","keywords":"","version":"Next"},{"title":"ICE Servers​","type":1,"pageTitle":"Peer-to-Peer Connection","url":"/docs/design/peer-to-peer/#ice-servers","content":" ICE (Interactive Connectivity Establishment) is a framework used by WebRTC (among other technologies) for connecting two peers, regardless of network topology (usually for audio and video chat). This protocol lets two peers find and establish a connection with one another even though they may both be using Network Address Translator (NAT) to share a global IP address with other devices on their respective local networks. https://developer.mozilla.org/en-US/docs/Glossary/ICE  ","version":"Next","tagName":"h2"},{"title":"STUN​","type":1,"pageTitle":"Peer-to-Peer Connection","url":"/docs/design/peer-to-peer/#stun","content":" STUN is an API used to obtain the IP address, port number, and connectivity status of a client running behind a firewall.    When a Client initiates a STUN request, it sends a Binding Request to the STUN server. The NAT/Router will then forward the request to the STUN server, which will respond with a Binding Response containing the public IP address and port number of the NAT/Router. The NAT/Router will then forward the Binding Response to the Client. The client now knows its public IP address and port number, which it can use to communicate with other clients.  warning If your NAT/Router uses Symmetric NAT, it will require a different NAT entry for each destination IP address meaning a direct peer-to-peer connection will not be able to be established between two clients. In this case, you will need to use a TURN server.  The Pod Arcade Server component includes a STUN server out of the box. If you are self hosting this component, consider not only port-forwarding the HTTP port, but also the STUN port. You can configure the STUN port using the STUN_PORT environment variable.  If you want to instead use a public STUN server, you can use the following configuration or replace it with any other STUN server of your choice. https://gist.github.com/zziuni/3741933 has a currated list of free STUN servers.  [{&quot;urls&quot;:[&quot;stun:stun.l.google.com:19302&quot;]}]   ","version":"Next","tagName":"h3"},{"title":"TURN​","type":1,"pageTitle":"Peer-to-Peer Connection","url":"/docs/design/peer-to-peer/#turn","content":" In the event that WebRTC is unable to establish a direct connection between the Desktop and the Browser, it will attempt to use a TURN server to relay the traffic. This is a last resort, as it will add latency to your Pod Arcade sessions. In this scenario, all traffic between the Desktop and the Browser will be routed through the TURN server.    The Pod Arcade Server component does not include a TURN server out of the box. You will need to run your own TURN server and configure it using the ICE_SERVERS environment variable.  During development, the Pod Arcade team used Stunner, a Kubernetes native STUN/TURN server. With that you can configure a static username and password and then configure the Pod Arcade Server component to use it like so:  [ {&quot;urls&quot;:[&quot;stun:10.0.0.10:3478?transport=udp&quot;]}, {&quot;urls&quot;:[&quot;turn:{{private_ip}}:3478?transport=udp&quot;,&quot;turn:{{public_ip}}:3478?transport=udp&quot;],&quot;username&quot;:&quot;user-1&quot;,&quot;credential&quot;:&quot;pass-1&quot;} ]   ","version":"Next","tagName":"h3"},{"title":"Port Forwarding​","type":1,"pageTitle":"Peer-to-Peer Connection","url":"/docs/design/peer-to-peer/#port-forwarding","content":" If none of the ICE methods work above, you will need to configure the Pod Arcade Desktop component with a static port number and then configure your router to forward that port to the Pod Arcade Desktop component. In this mode, all WebRTC connections will be established to a static port, allowing a direct peer-to-peer connection to be established.    You can configure the port number using the WEBRTC_IPS and WEBRTC_PORT environment variables. The WEBRTC_IPS variable should be set to the public IP address of your NAT/Router (and optionally the private IP address of the server the Desktop is running). The WEBRTC_PORT variable should be set to the port number you have port-forwarded through from your router.  info The port number of the Pod Arcade Desktop component must be the same as the port number configured on your router in order for the configuration to work correctly.  If you are running multiple Desktops in your network, you will need to configure each Desktop with a unique port number and configure your router to forward each port to the corresponding Desktop. ","version":"Next","tagName":"h2"},{"title":"Streaming","type":0,"sectionRef":"#","url":"/docs/design/streaming/","content":"","keywords":"","version":"Next"},{"title":"Video Codecs​","type":1,"pageTitle":"Streaming","url":"/docs/design/streaming/#video-codecs","content":" There are many great video codecs to choose from. Being that Pod Arcade is a game streaming platform, the most important factor is latency. The lower the latency, the better the experience. In order to get the lowest latency possible, we have to choose a codec that can be encoded and decoded using hardware acceleration. We also need to choose a codec that can be used by WebRTC in (most) browsers.  RFC 7742 specifies that all WebRTC-compatible browsers must support VP8 and H.264's Constrained Baseline profile for video. Most devices already have H.264 hardware acceleration built in, and is supported by all major browsers so we will use H.264 for video.  Codec\tEncoding\tDecoding\tCompatibility\tCompressionH.264\tHardware\tHardware\tAll Browsers\tGood H.265\tHardware\tHardware\tSafari\tGreat VP8\tHardware\tHardware\tAll Browsers\tPoor VP9\tHardware\tHardware\tAll Browsers\tGreat AV1\tSoftware\tSoftware\tChrome\tAmazing  H.265 is a great codec, but it is not supported by all browsers, specifically only supported by Safari. It is also not supported by all hardware, and the ecosystem around the codec is very proprietary and closed. For these reasons, we will not be using H.265.  VP9 is also a potential candidate, but hasn't been evaluated yet. This is the same codec used by most cloud game streaming services, so may provide a valid alternative to H.264 if the latency is low enough on lower-powered hardware.  And finally AV1 would be a perfect candidate for remote streaming, but encoding performance is still not great, and decoding performance is even worse. This codec will be re-evaluated in the future as more hardware support is added.  In the desktop application, video is captured using the wf-recorder and piped into Pod Arcade to be packetized and streamed via WebRTC. We hope in the future to migrate this over to Gstreamer to give us more control over the video stream, and allow us to have greater hardware compatibility.  ","version":"Next","tagName":"h2"},{"title":"Packet loss​","type":1,"pageTitle":"Streaming","url":"/docs/design/streaming/#packet-loss","content":" When designing Pod Arcade we had to be very considerate of packet loss throughout the whole process. Packet loss can occur at any point between the Desktop and the Browser, and can be caused by a number of different factors. The most common cause of packet loss is a poor WiFi connection, but it can also be caused by a poor internet connection, or even a poor connection between the Desktop and the Router.    Whenever a packet is lost, the video stream will freeze until the next packet is received. This can be very jarring and can ruin the experience. In order to mitigate this, WebRTC implements a feature called a Jitter Buffer. The Jitter Buffer will store a number of packets in memory, and will play them back in order, giving ample time for missed packets to be redelivered when it is lost. This will help smooth out the video stream, but will also add latency.  For systems like Moonlight, a jitter buffer is not used. Instead, there is a tighter integration between the streaming client and the video encoder, and whenever a packet is missed, the video encoder will generate a new IDR frame, which will allow the video stream to recover much faster. While overal latency is lower, during high packet loss this can cause the video stream to become very blocky and pixelated, or potentially even use more bandwidth, causing additional pressure to a system that is already losing packets.  We continue to evaluate the best way to handle packet loss, and may implement a similar feature in the future. In the meantime we are working with the WebRTC community to help improve the Jitter Buffer implementation and specifically make the delivery of these packets more robust to keep the latency as low as possible.  ","version":"Next","tagName":"h2"},{"title":"Audio​","type":1,"pageTitle":"Streaming","url":"/docs/design/streaming/#audio","content":" Audio is streamed using the Opus codec. Opus is a great codec for streaming audio, and is supported by all major browsers. It is also supported by most hardware, and is very efficient. It is also a great codec for low-latency audio, which is crucial for a good gaming experience. The alternative to this is G.711, but in our testing has shown to have really low audio quality.  In the desktop application all audio is captured from the PulseAudio server using Gstreamer, which is then piped into Pod Arcade to be streamed to the browser. ","version":"Next","tagName":"h2"},{"title":"Input Emulation","type":0,"sectionRef":"#","url":"/docs/design/input-emulation/","content":"","keywords":"","version":"Next"},{"title":"Gamepad​","type":1,"pageTitle":"Input Emulation","url":"/docs/design/input-emulation/#gamepad","content":" One of the challenges that Pod Arcade had to overcome was the the creation of virtual gamepad devices inside of Docker, and expose them using the udev interface in Linux. Unfortunately, uinput and udevd aren't container aware, so we can only do so much to keep things isolated to containers. While we are able to control device visibility inside of our containers, we aren't able to prevent the host from seeing those virtual devices. As a result, it's recommended that you only use this on a headless server, not a workstation.  This code aims to utilize the same uinput and udev APIs to work with existing software for discovering these virtual gamepads.    ","version":"Next","tagName":"h2"},{"title":"1. Connect​","type":1,"pageTitle":"Input Emulation","url":"/docs/design/input-emulation/#1-connect","content":" Our application starts up, and opens a connection to the Kernel. This connection will be used to receive events when devices are created. The reason we need this, is that we can't simply emit events directly without knowing the device information assigned by the Kernel. As far as I know, the only way of receiving this information is to listen for those Kevents sent by the kernel. Opening this socket looks like this:   // ... const ( KernelEvent Mode = 1 UdevEvent Mode = 2 ) // ... if c.Fd, err = syscall.Socket(syscall.AF_NETLINK, syscall.SOCK_RAW, syscall.NETLINK_KOBJECT_UEVENT); err != nil { return } c.Addr = syscall.SockaddrNetlink{ Family: syscall.AF_NETLINK, Groups: uint32(mode), // Mode determines the group, Kernel or Udev } if err = syscall.Bind(c.Fd, &amp;c.Addr); err != nil { syscall.Close(c.Fd) } // ...   Crucially, one other thing that we need to do is create the /run/udev directory, and create a /run/udev/control file. These files aren't used for anything, but the libudev library checks for the existence of these files to ensure that an instance of udev is running. It never reads to or writes to this file, only checks for its existence before subscribing to udev events.  ","version":"Next","tagName":"h3"},{"title":"2. Connect (Application Side)​","type":1,"pageTitle":"Input Emulation","url":"/docs/design/input-emulation/#2-connect-application-side","content":" Similar to how we subscribe to the Kernel group to receive device events over the netlink socket, applications normally subscribe to the Udev group.  Udevd is the userspace program that typically listens to these events from the kernel, enriches them with information from a hardware database, and re-emits them. It also has a set of rules that it executes when messages from the kernel match a set of filters. These rules can be used to do things like run a program that calibrates the joystick device, or other various things that don't have a direct subscription to Udev. Applications typically subscribe to this using libudev, which is a library used for interacting with the userspace daemon.  In our case, we're aiming to replace much of this userspace program's functionality. We have to do some trickery in order to get libudev to actually believe that there's a running udev instance and make the subscription. We do this by touching the /run/udev/control file.  ","version":"Next","tagName":"h3"},{"title":"3. Create a gamepad using /dev/uinput​","type":1,"pageTitle":"Input Emulation","url":"/docs/design/input-emulation/#3-create-a-gamepad-using-devuinput","content":" The /dev/uinput interface serves as a user-space API for creating and managing input devices at the kernel level. In essence, it enables you to create virtual input devices such as keyboards, mice, joysticks, or gamepads that the operating system treats as actual hardware devices. In order to use this interface, we need to bind through the host's interface.  note This isn't technically true. We can use mknod to recreate the /dev/uinput file, as long as we have the major:minor version supplied by the kernel, but mounting it through is the easiest way. c10:223 is what the device was on my machine, but I'm not sure if it's the same for everyone. stat --format=&quot;%t %T&quot; /dev/uinput should give you the device numbers in hexadecimal format  Regardless, by writing ioctl commands to this device, we can create a Virtual Gamepad.  ","version":"Next","tagName":"h3"},{"title":"4. Kernel — Load gamepad driver and populate /sys directory​","type":1,"pageTitle":"Input Emulation","url":"/docs/design/input-emulation/#4-kernel--load-gamepad-driver-and-populate-sys-directory","content":" The Kernel takes those ioctl commands, and loads the appropriate input driver. I'm not sure exactly how all of that happens, but it then creates the /sys directory entry for that device, in /sys/devices/virtual/input/. Unfortunately, this stage is NOT restricted to your container. The /sys entry is created in every container, and on the host. Additionally, the events emitted in the next step are also emitted to everyone. This means that if your host is running udevd (which it likely is), those virtual devices will show up on your host. We're investigating ways of preventing this, but for now... virtual devices created in your container will show up on the host as well.  ","version":"Next","tagName":"h3"},{"title":"5. Broadcast Kevent​","type":1,"pageTitle":"Input Emulation","url":"/docs/design/input-emulation/#5-broadcast-kevent","content":" When a device is connected, the kernel writes a message that looks something like this over the netlink socket we're subscribed to. It's a series of strings that represents device information. It always begins with a header that sigals what the ACTION is and on what DEVPATH it occurs on.  add@/class/input/input9/mouse2\\0 ACTION=add\\0 DEVPATH=/class/input/input9/mouse2\\0 SUBSYSTEM=input\\0 SEQNUM=1064\\0 PHYSDEVPATH=/devices/pci0000:00/0000:00:1d.1/usb2/2­2/2­2:1.0\\0 PHYSDEVBUS=usb\\0 PHYSDEVDRIVER=usbhid\\0 MAJOR=13\\0 MINOR=34\\0   ","version":"Next","tagName":"h3"},{"title":"6. Receive device created Kevent​","type":1,"pageTitle":"Input Emulation","url":"/docs/design/input-emulation/#6-receive-device-created-kevent","content":" Our application receives and parses the message sent from the kernel. This gets it ready for step 7.  ","version":"Next","tagName":"h3"},{"title":"7. Map device to a local path​","type":1,"pageTitle":"Input Emulation","url":"/docs/design/input-emulation/#7-map-device-to-a-local-path","content":" Now that we have the device major and minor number, we can map this to a file in our container. When determining if we should process a message from the given &lt;DEVNAME&gt;, we compare it to the syspath queried using ioctl for our gamepad.  Because we may have multiple containers, the event for one of our virtual gamepads may come in looking like: add@/devices/virtual/input/input378/js4. Unfortunately, some legacy applications don't look for gamepad devices beyond js0-3. This isn't as much of a problem with programs that use the new libevdev devices, but for older ones, they won't detect the newly plugged in gamepad. Instead, we map this js4 device back to js0 for our container. This doesn't affect the path assigned by the Kernel, but any further events emitted from our application will now use the mapped js0-3.  Additionally, we need to map not just the legacy jsX devices, but also the eventXYZ devices. If it's the eventXYZ, we don't make any changes and map the device as is.  If we find a match, we know that the device belongs to us. If it's a legacy jsX device, we'll map it to it's index in our gamepad hub. Both of these devices are mapped to /dev/input/js0-3, or /dev/input/eventXYZ.  ","version":"Next","tagName":"h3"},{"title":"8. Call mknod with the device's major and minor version​","type":1,"pageTitle":"Input Emulation","url":"/docs/design/input-emulation/#8-call-mknod-with-the-devices-major-and-minor-version","content":" Once we've mapped it to the desired path, we'll make syscalls equivalent to mknod c &lt;major&gt; &lt;minor&gt; /dev/input/jsX and mknod c &lt;major&gt; &lt;minor&gt; /dev/input/eventXYZ.  ","version":"Next","tagName":"h3"},{"title":"9. Resend the Kernel's event as a Udev event​","type":1,"pageTitle":"Input Emulation","url":"/docs/design/input-emulation/#9-resend-the-kernels-event-as-a-udev-event","content":" After we create the local device path using mknod, we can modify and resend the events using the udev format. This is an internal format used only by udevd and libudev. The format of this additional message looks something like this:  // C code taken from device-monitor.c typedef struct monitor_netlink_header { /* &quot;libudev&quot; prefix to distinguish libudev and kernel messages */ char prefix[8]; /* Magic to protect against daemon &lt;-&gt; Library message format mismatch * Used in the kernel from socket filter rules; needs to be stored in network order */ unsigned magic; /* Total length of header structure known to the sender */ unsigned header_size; /* Properties string buffer */ unsigned properties_off; unsigned properties_len; /* Hashes of primary device properties strings, to let libudev subscribers * use in-kernel socket filters; values need to be stored in network order */ unsigned filter_subsystem_hash; unsigned filter_devtype_hash; unsigned filter_tag_bloom_hi; unsigned filter_tag_bloom_lo; } monitor_netlink_header;   8 bytes of &quot;libudev&quot; 4 bytes of 0xfeedcafe 4 bytes of header size X bytes of header ACTION=add\\0 DEVPATH=/class/input/input9/mouse2\\0 SUBSYSTEM=input\\0 SEQNUM=1064\\0 PHYSDEVPATH=/devices/pci0000:00/0000:00:1d.1/usb2/2­2/2­2:1.0\\0 PHYSDEVBUS=usb\\0 PHYSDEVDRIVER=usbhid\\0 MAJOR=13\\0 MINOR=34\\0   ","version":"Next","tagName":"h3"},{"title":"10. Application Receives a notification from \"udevd\"​","type":1,"pageTitle":"Input Emulation","url":"/docs/design/input-emulation/#10-application-receives-a-notification-from-udevd","content":" Now that we've forged our udev message, the application subscribed should receive it, and treat it as though it was a real message emitted from udevd.  ","version":"Next","tagName":"h3"},{"title":"11. Application opens virtual device​","type":1,"pageTitle":"Input Emulation","url":"/docs/design/input-emulation/#11-application-opens-virtual-device","content":" From the DEVPATH extracted from the received message, the corresponding libevdev or legacy uapi joystick library. Once connected to that device, the application should be able to use it as normal.  ","version":"Next","tagName":"h3"},{"title":"Keyboard / Mouse​","type":1,"pageTitle":"Input Emulation","url":"/docs/design/input-emulation/#keyboard--mouse","content":" Keyboard and mouse emulation, instead of being done through udev devices in the Kernal, is done through wl-roots APIs directly. This is because the Kernal doesn't have a concept of a virtual keyboard or mouse, and instead relies on the compositor to handle these events. If we were to emulate a keyboard or mouse using udev, these devices may inadvertently be used by a shell that is running on the headless server, and may cause unintended side effects.  Instead, we use the virtual-keyboard-unstable-v1 and wlr-virtual-pointer-unstable-v1 interfaces provided by wl-roots (and therefore Sway). These protocols are described using XML documents and are used to generate code to interact with the compositor. This code is generated by https://github.com/rajveermalviya/go-wayland/.  ","version":"Next","tagName":"h2"},{"title":"Helpful References​","type":1,"pageTitle":"Input Emulation","url":"/docs/design/input-emulation/#helpful-references","content":" https://documentation.suse.com/sles/12-SP5/html/SLES-all/cha-udev.htmlhttps://insujang.github.io/2018-11-27/udev-device-manager-for-the-linux-kernel-in-userspace/https://github.com/systemd/systemd/blob/main/src/libudev/libudev-monitor.chttps://github.com/pilebones/go-udevhttps://docs.voidlinux.org/config/session-management.htmlhttps://www.freedesktop.org/wiki/Software/systemd/multiseat/ ","version":"Next","tagName":"h2"},{"title":"Docker","type":0,"sectionRef":"#","url":"/docs/getting-started/docker/","content":"","keywords":"","version":"Next"},{"title":"Docker Compose​","type":1,"pageTitle":"Docker","url":"/docs/getting-started/docker/#docker-compose","content":" There's docker-compose for running desktops in pod-arcade/example-apps  You'll need to set some of the environment variables to have it connect to the Pod Arcade server. Just be careful which example applications you look at. Many of those pod-arcade/example-apps simply use the built in VNC server to stream the desktop to the browser, not Pod Arcade. That's because it's much faster to do development that way, and will be compatible with pod-arcade if the VNC approach works. ","version":"Next","tagName":"h3"},{"title":"Introduction","type":0,"sectionRef":"#","url":"/docs/intro/","content":"Introduction Pod Arcade is an open-source project that enables you to stream games via RetroArch or other compatible software, running on Wayland, directly to your web browser. It is designed to be deployed on Kubernetes, but can also be deployed using Docker or any other container platform. There are two major components to Pod Arcade: Server — an MQTT server that manages the game streaming sessions. Desktops and web browsers connect to this server in order to stream games.Desktop — a server that runs on Wayland which streams games to the web browser and emulates input devices. All Pod Arcade communication between the Desktop component and the web browsers is done using WebRTC. WebRTC uses an algorithm called ICE to attempt to establish a direct connection between the Desktop and the Browser. In most cases, this will work without any additional configuration. However, if you are behind a firewall or NAT, you may need to configure your router to forward ports to your Pod Arcade server or add a TURN server to your Pod Arcade server configuration.","keywords":"","version":"Next"},{"title":"Kubernetes (Helm)","type":0,"sectionRef":"#","url":"/docs/getting-started/helm/","content":"Kubernetes (Helm) We provide some reference helm charts for deploying Pod Arcade on Kubernetes, at pod-arcade/charts. This is what we use to deploy Pod Arcade during development, and is likely the easiest way to get started. To get started simply add the helm repository: helm repo add pod-arcade https://charts.pod-arcade.com Then install the server component: helm install pa-server pod-arcade/server you can find the values.yaml file for the server chart here. Reference the server configuration for more information on the configuration options. Then install a desktop component: helm install pa-desktop pod-arcade/desktop-sidecar the values.yaml file for the desktop chart can be found here. Reference the desktop configuration for more information on the configuration options.","keywords":"","version":"Next"}],"options":{"id":"default"}}